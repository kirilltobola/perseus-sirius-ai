{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cc676a-6395-4537-980a-026dccd04d06",
   "metadata": {},
   "source": [
    "### В этом блокноте мы рассмотрим методы оценки задач абстрактной суммаризации на простом примере. Мы изучим традиционные методы оценки, такие как ROUGE и BERTScore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087925b-36e3-4d38-bbc8-93a7d0578ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rouge --quiet\n",
    "# !pip install bert_score --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c9431-a611-4de8-a3d5-8e411427a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a747a5-6dff-49c4-9535-d62be735456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Python Implementation of the ROUGE Metric\n",
    "from rouge import Rouge\n",
    "\n",
    "# BERTScore leverages the pre-trained contextual embeddings from BERT and matches words in candidate and reference sentences by cosine similarity.\n",
    "from bert_score import BERTScorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9197da-d36a-4241-9ba1-8e91daa395b0",
   "metadata": {},
   "source": [
    "# Example task\n",
    "Для целей этого блокнота мы будем использовать пример саммари, приведенный ниже. Обратите внимание, что мы предоставляем два сгенерированных саммари для сравнения, а также эталонное резюме, написанное человеком, которое требуется для таких метрик оценки, как ROUGE и BERTScore.\n",
    "\n",
    "Отрывок (фрагмент):\n",
    "\n",
    "```OpenAI's mission is to ensure that artificial general intelligence (AGI) benefits all of humanity. OpenAI will build safe and beneficial AGI directly, but will also consider its mission fulfilled if its work aids others to achieve this outcome. OpenAI follows several key principles for this purpose. First, broadly distributed benefits - any influence over AGI's deployment will be used for the benefit of all, and to avoid harmful uses or undue concentration of power. Second, long-term safety - OpenAI is committed to doing the research to make AGI safe, and to promote the adoption of such research across the AI community. Third, technical leadership - OpenAI aims to be at the forefront of AI capabilities. Fourth, a cooperative orientation - OpenAI actively cooperates with other research and policy institutions, and seeks to create a global community working together to address AGI's global challenges.```\n",
    "\n",
    "Саммари:\n",
    "\n",
    "Референс Summary `/ref_summary` (сгенерированное человеком)\t\n",
    "\n",
    "```OpenAI aims to ensure artificial general intelligence (AGI) is used for everyone's benefit, avoiding harmful uses or undue power concentration. It is committed to researching AGI safety, promoting such studies among the AI community. OpenAI seeks to lead in AI capabilities and cooperates with global research and policy institutions to address AGI's challenges.```\n",
    "\n",
    "Eval Summary 1 / eval_summary_1 (system generated)\n",
    "\n",
    "```OpenAI aims to AGI benefits all humanity, avoiding harmful uses and power concentration. It pioneers research into safe and beneficial AGI and promotes adoption globally. OpenAI maintains technical leadership in AI while cooperating with global institutions to address AGI challenges. It seeks to lead a collaborative worldwide effort developing AGI for collective good.```\n",
    "\n",
    "Eval Summary 2 / eval_summary_2 (system generated)\n",
    "\n",
    "```OpenAI aims to ensure AGI is for everyone's use, totally avoiding harmful stuff or big power concentration. Committed to researching AGI's safe side, promoting these studies in AI folks. OpenAI wants to be top in AI things and works with worldwide research, policy groups to figure AGI's stuff.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36029a7c-c168-4f52-895e-dad76e3aebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpt = \"OpenAI's mission is to ensure that artificial general intelligence (AGI) benefits all of humanity. OpenAI will build safe and beneficial AGI directly, but will also consider its mission fulfilled if its work aids others to achieve this outcome. OpenAI follows several key principles for this purpose. First, broadly distributed benefits - any influence over AGI's deployment will be used for the benefit of all, and to avoid harmful uses or undue concentration of power. Second, long-term safety - OpenAI is committed to doing the research to make AGI safe, and to promote the adoption of such research across the AI community. Third, technical leadership - OpenAI aims to be at the forefront of AI capabilities. Fourth, a cooperative orientation - OpenAI actively cooperates with other research and policy institutions, and seeks to create a global community working together to address AGI's global challenges.\"\n",
    "ref_summary = \"OpenAI aims to ensure artificial general intelligence (AGI) is used for everyone's benefit, avoiding harmful uses or undue power concentration. It is committed to researching AGI safety, promoting such studies among the AI community. OpenAI seeks to lead in AI capabilities and cooperates with global research and policy institutions to address AGI's challenges.\"\n",
    "eval_summary_1 = \"OpenAI aims to AGI benefits all humanity, avoiding harmful uses and power concentration. It pioneers research into safe and beneficial AGI and promotes adoption globally. OpenAI maintains technical leadership in AI while cooperating with global institutions to address AGI challenges. It seeks to lead a collaborative worldwide effort developing AGI for collective good.\"\n",
    "eval_summary_2 = \"OpenAI aims to ensure AGI is for everyone's use, totally avoiding harmful stuff or big power concentration. Committed to researching AGI's safe side, promoting these studies in AI folks. OpenAI wants to be top in AI things and works with worldwide research, policy groups to figure AGI's stuff.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d63f6a-4603-4009-a08e-9ea79d407b52",
   "metadata": {},
   "source": [
    "## Evaluating using ROUGE\n",
    "\n",
    "**ROUGE** (Recall-Oriented Understudy for Gisting Evaluation), в первую очередь оценивает совпадение слов между сгенерированным результатом и эталонным текстом. Это распространенная метрика для оценки задач автоматической суммаризации. Среди ее разновидностей есть `ROUGE-L`, которая позволяет определить, насколько хорошо система сохраняет суть оригинального саммари - это самое длинное непрерывное совпадение между сгенерированным системой и эталонным саммари."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba69b9e-cc2c-4081-8d70-a68d52190c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the Rouge score\n",
    "def get_rouge_scores(text1, text2):\n",
    "    rouge = Rouge()\n",
    "    return rouge.get_scores(text1, text2)\n",
    "\n",
    "\n",
    "rouge_scores_out = []\n",
    "\n",
    "# Calculate the ROUGE scores for both summaries using reference\n",
    "eval_1_rouge = get_rouge_scores(eval_summary_1, ref_summary)\n",
    "eval_2_rouge = get_rouge_scores(eval_summary_2, ref_summary)\n",
    "\n",
    "for metric in [\"rouge-1\", \"rouge-2\", \"rouge-l\"]:\n",
    "    for label in [\"F-Score\"]:\n",
    "        eval_1_score = eval_1_rouge[0][metric][label[0].lower()]\n",
    "        eval_2_score = eval_2_rouge[0][metric][label[0].lower()]\n",
    "\n",
    "        row = {\n",
    "            \"Metric\": f\"{metric} ({label})\",\n",
    "            \"Summary 1\": eval_1_score,\n",
    "            \"Summary 2\": eval_2_score,\n",
    "        }\n",
    "        rouge_scores_out.append(row)\n",
    "\n",
    "\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return [\n",
    "        \"background-color: lightgreen\" if v else \"background-color: white\"\n",
    "        for v in is_max\n",
    "    ]\n",
    "\n",
    "\n",
    "rouge_scores_out = (\n",
    "    pd.DataFrame(rouge_scores_out)\n",
    "    .set_index(\"Metric\")\n",
    "    .style.apply(highlight_max, axis=1)\n",
    ")\n",
    "\n",
    "rouge_scores_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef5530-8a31-41ba-9445-582e7b521fa7",
   "metadata": {},
   "source": [
    "В таблице показаны оценки ROUGE для оценки двух различных саммари по сравнению с эталонным текстом. \n",
    "В случае с rouge-1 саммари 2 превосходит саммари 1, что свидетельствует о лучшем совпадении отдельных слов, а в случае с rouge-l саммари 2 имеет более высокий балл, что означает более тесное совпадение по самым длинным общим подпоследовательностям и, таким образом, потенциально лучшее общее обобщение, передающее основное содержание и порядок оригинального текста. \n",
    "\n",
    "Поскольку в саммари 2 много слов и коротких фраз, взятых непосредственно из отрывка, его совпадение с эталонным резюме, скорее всего, будет выше, что приведет к более высоким оценкам ROUGE.\n",
    "\n",
    "Хотя ROUGE и аналогичные метрики, такие как BLEU и METEOR, предлагают количественные показатели, они часто не отражают истинную суть хорошо сгенерированного саммари. Кроме того, они хуже коррелируют с человеческими оценками. Учитывая развитие LLM, которые умеют создавать беглые и связные саммари, традиционные метрики, такие как ROUGE, могут невольно штрафовать эти модели. Это особенно верно, если саммари сформулированы по-разному, но при этом точно отражают основную информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb78950-06d6-41f4-a315-395f6324e367",
   "metadata": {},
   "source": [
    "## Evaluating using BERTScore\n",
    "\n",
    "ROUGE опирается на точное присутствие слов в предсказанных и эталонных текстах, не умея интерпретировать лежащую в их основе семантику. Именно здесь на помощь приходит BERTScore, который использует контекстуальные эмбеддинги из модели BERT, стремясь оценить сходство между предсказанным и эталонным предложением в контексте текста, созданного машиной. Сравнивая эмбеддинги из обоих предложений, BERTScore улавливает семантическое сходство, которое может быть упущено традиционными метриками, основанными на n-граммах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b08bfe-e8d4-4ea6-9821-3209a476a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the BERTScorer object for English language\n",
    "scorer = BERTScorer(lang=\"en\")\n",
    "\n",
    "# Calculate BERTScore for the summary 1 against the excerpt\n",
    "# P1, R1, F1_1 represent Precision, Recall, and F1 Score respectively\n",
    "P1, R1, F1_1 = scorer.score([eval_summary_1], [ref_summary])\n",
    "\n",
    "# Calculate BERTScore for summary 2 against the excerpt\n",
    "# P2, R2, F2_2 represent Precision, Recall, and F1 Score respectively\n",
    "P2, R2, F2_2 = scorer.score([eval_summary_2], [ref_summary])\n",
    "\n",
    "print(\"Summary 1 F1 Score:\", F1_1.tolist()[0])\n",
    "print(\"Summary 2 F1 Score:\", F2_2.tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f31f7-30c1-4247-83cf-2eb1fe153115",
   "metadata": {},
   "source": [
    "Близкие показатели F1 между саммари указывают на то, что они могут одинаково эффективно отражать ключевую информацию. Однако эту небольшую разницу следует интерпретировать с осторожностью. Поскольку BERTScore может не полностью улавливать тонкости и высокоуровневые понятия, которые может понять человек, опирающийся на эту метрику, может привести к неправильной интерпретации фактического качества и нюансов саммари. Интегрированный подход, сочетающий BERTScore с человеческим суждением и другими метриками, может предложить более надежную оценку."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
